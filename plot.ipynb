{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "img1=np.random.randint(0,255,size=(5,10)) \n",
    "plt.matshow(img1, cmap='gray')\n",
    "plt.title(\"matrix A\")\n",
    "plt.show()\n",
    "plt.savefig('img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyData(x=[63, 31], pos=[63, 1, 3], num_nodes=63, channel_weights=[63, 1], num_residues=63, chain=[63], edge_index=[2, 316], edge_relations=[316], edge_weights=[316], num_relation=6, affinities=[1, 2], functions=[1, 3293], valid_masks=[1, 4], chains=[63], lig_flag=[63], prot_id='1A0A-A', type='multi')\n",
      "MyData(x=[498], edge_index=[2, 4305], pos=[498, 3], edge_weights=[4305], affinities=[1, 2], functions=[1, 3293], valid_masks=[1, 4], chains=[498], lig_flag=[498], prot_id='1A0A-A', type='multi')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "graph_a = torch.load(\"./datasets/MultiTask_c03_id09/graphs_new/hetero_alphaonly_knn5_spatial4.5_sequential2_train_all/1A0A-A.pt\")\n",
    "graph_b = torch.load(\"./datasets/MultiTask_c03_id09/graphs_new/hetero_alphaonly_forhemenet_knn5_spatial4.5_sequential2_train_all/1A0A-A.pt\")\n",
    "graph_c = torch.load(\"./datasets/MultiTask_c03_id09/graphs_new/fullatom_knn9_spatial4.5_sequential2_train_all/1A0A-A.pt\")\n",
    "\n",
    "print(graph_a)\n",
    "print(graph_b)\n",
    "print(graph_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(None, -1, None) slice(1, None, None)\n",
      "[1, 2, 3, 4]\n",
      "[2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "x = [1, 2, 3, 4, 5]\n",
    "a = slice(-i)\n",
    "b = slice(i, None)\n",
    "print(a, b)\n",
    "print(x[a])\n",
    "print(x[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 15\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "with open('./GMSL/datasets/MultiTask/uniformed_labels.json', 'r') as f:\n",
    "    label_info = json.load(f)\n",
    "graph_cache_dir = './GMSL/datasets/MultiTask_c03_id09/graphs_new/hetero_alphaonly_forhemenet_knn5_spatial4.5_sequential2_test'\n",
    "complex_files = os.listdir(graph_cache_dir)\n",
    "lba_complexes = []\n",
    "ppi_complexes = []\n",
    "for item in complex_files:\n",
    "    if label_info[item[:-3]]['lba'] != -1:\n",
    "        lba_complexes.append(item)\n",
    "    elif label_info[item[:-3]]['ppi'] != -1:\n",
    "        ppi_complexes.append(item)\n",
    "print(len(lba_complexes), len(ppi_complexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MultiTask Model...\n",
      "Readout Strategy: task_aware_attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model consists of 59798791 trainable params.\n",
      "model.affinity_prompts\n",
      "model.property_prompts\n",
      "model.init_embedding.weight\n",
      "model.channel_attr.weight\n",
      "model.edge_attr.weight\n",
      "model.gnn.layers.0.w_r\n",
      "model.gnn.layers.0.batch_norm.weight\n",
      "model.gnn.layers.0.batch_norm.bias\n",
      "model.gnn.layers.0.radial_linear.weight\n",
      "model.gnn.layers.0.radial_linear.bias\n",
      "model.gnn.layers.0.hetero_linear.weight\n",
      "model.gnn.layers.0.hetero_linear.bias\n",
      "model.gnn.layers.0.message_mlp.0.weight\n",
      "model.gnn.layers.0.message_mlp.0.bias\n",
      "model.gnn.layers.0.message_mlp.2.weight\n",
      "model.gnn.layers.0.message_mlp.2.bias\n",
      "model.gnn.layers.0.coord_mlp.0.weight\n",
      "model.gnn.layers.0.coord_mlp.0.bias\n",
      "model.gnn.layers.0.coord_mlp.2.weight\n",
      "model.gnn.layers.1.w_r\n",
      "model.gnn.layers.1.batch_norm.weight\n",
      "model.gnn.layers.1.batch_norm.bias\n",
      "model.gnn.layers.1.radial_linear.weight\n",
      "model.gnn.layers.1.radial_linear.bias\n",
      "model.gnn.layers.1.hetero_linear.weight\n",
      "model.gnn.layers.1.hetero_linear.bias\n",
      "model.gnn.layers.1.message_mlp.0.weight\n",
      "model.gnn.layers.1.message_mlp.0.bias\n",
      "model.gnn.layers.1.message_mlp.2.weight\n",
      "model.gnn.layers.1.message_mlp.2.bias\n",
      "model.gnn.layers.1.coord_mlp.0.weight\n",
      "model.gnn.layers.1.coord_mlp.0.bias\n",
      "model.gnn.layers.1.coord_mlp.2.weight\n",
      "model.gnn.layers.2.w_r\n",
      "model.gnn.layers.2.batch_norm.weight\n",
      "model.gnn.layers.2.batch_norm.bias\n",
      "model.gnn.layers.2.radial_linear.weight\n",
      "model.gnn.layers.2.radial_linear.bias\n",
      "model.gnn.layers.2.hetero_linear.weight\n",
      "model.gnn.layers.2.hetero_linear.bias\n",
      "model.gnn.layers.2.message_mlp.0.weight\n",
      "model.gnn.layers.2.message_mlp.0.bias\n",
      "model.gnn.layers.2.message_mlp.2.weight\n",
      "model.gnn.layers.2.message_mlp.2.bias\n",
      "model.gnn.layers.2.coord_mlp.0.weight\n",
      "model.gnn.layers.2.coord_mlp.0.bias\n",
      "model.gnn.layers.2.coord_mlp.2.weight\n",
      "model.gnn.layers.3.w_r\n",
      "model.gnn.layers.3.batch_norm.weight\n",
      "model.gnn.layers.3.batch_norm.bias\n",
      "model.gnn.layers.3.radial_linear.weight\n",
      "model.gnn.layers.3.radial_linear.bias\n",
      "model.gnn.layers.3.hetero_linear.weight\n",
      "model.gnn.layers.3.hetero_linear.bias\n",
      "model.gnn.layers.3.message_mlp.0.weight\n",
      "model.gnn.layers.3.message_mlp.0.bias\n",
      "model.gnn.layers.3.message_mlp.2.weight\n",
      "model.gnn.layers.3.message_mlp.2.bias\n",
      "model.gnn.layers.3.coord_mlp.0.weight\n",
      "model.gnn.layers.3.coord_mlp.0.bias\n",
      "model.gnn.layers.3.coord_mlp.2.weight\n",
      "model.gnn.layers.4.w_r\n",
      "model.gnn.layers.4.batch_norm.weight\n",
      "model.gnn.layers.4.batch_norm.bias\n",
      "model.gnn.layers.4.radial_linear.weight\n",
      "model.gnn.layers.4.radial_linear.bias\n",
      "model.gnn.layers.4.hetero_linear.weight\n",
      "model.gnn.layers.4.hetero_linear.bias\n",
      "model.gnn.layers.4.message_mlp.0.weight\n",
      "model.gnn.layers.4.message_mlp.0.bias\n",
      "model.gnn.layers.4.message_mlp.2.weight\n",
      "model.gnn.layers.4.message_mlp.2.bias\n",
      "model.gnn.layers.4.coord_mlp.0.weight\n",
      "model.gnn.layers.4.coord_mlp.0.bias\n",
      "model.gnn.layers.4.coord_mlp.2.weight\n",
      "model.gnn.layers.5.w_r\n",
      "model.gnn.layers.5.batch_norm.weight\n",
      "model.gnn.layers.5.batch_norm.bias\n",
      "model.gnn.layers.5.radial_linear.weight\n",
      "model.gnn.layers.5.radial_linear.bias\n",
      "model.gnn.layers.5.hetero_linear.weight\n",
      "model.gnn.layers.5.hetero_linear.bias\n",
      "model.gnn.layers.5.message_mlp.0.weight\n",
      "model.gnn.layers.5.message_mlp.0.bias\n",
      "model.gnn.layers.5.message_mlp.2.weight\n",
      "model.gnn.layers.5.message_mlp.2.bias\n",
      "model.gnn.layers.5.coord_mlp.0.weight\n",
      "model.gnn.layers.5.coord_mlp.0.bias\n",
      "model.gnn.layers.5.coord_mlp.2.weight\n",
      "model.gnn.layer_norms.0.weight\n",
      "model.gnn.layer_norms.0.bias\n",
      "model.gnn.layer_norms.1.weight\n",
      "model.gnn.layer_norms.1.bias\n",
      "model.gnn.layer_norms.2.weight\n",
      "model.gnn.layer_norms.2.bias\n",
      "model.gnn.layer_norms.3.weight\n",
      "model.gnn.layer_norms.3.bias\n",
      "model.gnn.layer_norms.4.weight\n",
      "model.gnn.layer_norms.4.bias\n",
      "model.gnn.layer_norms.5.weight\n",
      "model.gnn.layer_norms.5.bias\n",
      "model.affinity_heads.0.0.weight\n",
      "model.affinity_heads.0.0.bias\n",
      "model.affinity_heads.0.2.weight\n",
      "model.affinity_heads.0.2.bias\n",
      "model.affinity_heads.1.0.weight\n",
      "model.affinity_heads.1.0.bias\n",
      "model.affinity_heads.1.2.weight\n",
      "model.affinity_heads.1.2.bias\n",
      "model.property_heads.0.0.weight\n",
      "model.property_heads.0.0.bias\n",
      "model.property_heads.0.2.weight\n",
      "model.property_heads.0.2.bias\n",
      "model.property_heads.1.0.weight\n",
      "model.property_heads.1.0.bias\n",
      "model.property_heads.1.2.weight\n",
      "model.property_heads.1.2.bias\n",
      "model.property_heads.2.0.weight\n",
      "model.property_heads.2.0.bias\n",
      "model.property_heads.2.2.weight\n",
      "model.property_heads.2.2.bias\n",
      "model.property_heads.3.0.weight\n",
      "model.property_heads.3.0.bias\n",
      "model.property_heads.3.2.weight\n",
      "model.property_heads.3.2.bias\n",
      "model.global_readout.readout.0.query.weight\n",
      "model.global_readout.readout.0.query.bias\n",
      "model.global_readout.readout.0.key.weight\n",
      "model.global_readout.readout.0.key.bias\n",
      "model.global_readout.readout.0.value.weight\n",
      "model.global_readout.readout.0.value.bias\n",
      "model.global_readout.readout.0.linear.0.weight\n",
      "model.global_readout.readout.0.linear.0.bias\n",
      "model.global_readout.readout.0.linear.2.weight\n",
      "model.global_readout.readout.0.linear.2.bias\n",
      "model.global_readout.readout.0.layernorm1.weight\n",
      "model.global_readout.readout.0.layernorm1.bias\n",
      "model.global_readout.readout.0.layernorm2.weight\n",
      "model.global_readout.readout.0.layernorm2.bias\n",
      "model.global_readout.readout.0.linear1.weight\n",
      "model.global_readout.readout.0.linear1.bias\n",
      "model.global_readout.readout.0.linear2.weight\n",
      "model.global_readout.readout.0.linear2.bias\n",
      "model.chain_readout.readout.0.query.weight\n",
      "model.chain_readout.readout.0.query.bias\n",
      "model.chain_readout.readout.0.key.weight\n",
      "model.chain_readout.readout.0.key.bias\n",
      "model.chain_readout.readout.0.value.weight\n",
      "model.chain_readout.readout.0.value.bias\n",
      "model.chain_readout.readout.0.linear.0.weight\n",
      "model.chain_readout.readout.0.linear.0.bias\n",
      "model.chain_readout.readout.0.linear.2.weight\n",
      "model.chain_readout.readout.0.linear.2.bias\n",
      "model.chain_readout.readout.0.layernorm1.weight\n",
      "model.chain_readout.readout.0.layernorm1.bias\n",
      "model.chain_readout.readout.0.layernorm2.weight\n",
      "model.chain_readout.readout.0.layernorm2.bias\n",
      "model.chain_readout.readout.0.linear1.weight\n",
      "model.chain_readout.readout.0.linear1.bias\n",
      "model.chain_readout.readout.0.linear2.weight\n",
      "model.chain_readout.readout.0.linear2.bias\n",
      "Hello from rank 0\n",
      "Complexes for task multi is: 30904\n",
      "Complexes for task multi is: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./models/hemenet_vallina/lightning_logs/version_18/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexes for task multi is: 467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from the checkpoint at ./models/hemenet_vallina/lightning_logs/version_18/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [24520, 14] but got: [24520, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a657373652d643035227d/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(devices\u001b[39m=\u001b[39mdevice \u001b[39mif\u001b[39;00m device \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a657373652d643035227d/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m device \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m,)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a657373652d643035227d/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a657373652d643035227d/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(model\u001b[39m=\u001b[39;49mmodel, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./models/hemenet_vallina/lightning_logs/version_18/checkpoints/last.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m, dataloaders\u001b[39m=\u001b[39;49mdatamodule, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a657373652d643035227d/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a657373652d643035227d/home/rhan21/Research/DrugDD/GMSL_lite/GMSL/plot.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m time_diff \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:742\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    741\u001b[0m _verify_strategy_supports_compile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 742\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    743\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    744\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:785\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, test_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m    782\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    783\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    784\u001b[0m )\n\u001b[0;32m--> 785\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    786\u001b[0m \u001b[39m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    787\u001b[0m results \u001b[39m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mrun-stage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[0;32m-> 1016\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1018\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:376\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    375\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 376\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    380\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.test_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtest_step_context():\n\u001b[1;32m    402\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TestStep)\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtest_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/utils/task_models.py:276\u001b[0m, in \u001b[0;36mMultiTaskModel.test_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 276\u001b[0m     y_affinity_pred, y_property_pred, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(batch)\n\u001b[1;32m    277\u001b[0m     y_affinity_true \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39maffinities\n\u001b[1;32m    278\u001b[0m     y_property_true \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mfunctions\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/utils/task_models.py:153\u001b[0m, in \u001b[0;36mMultiTaskModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data: Batch) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor, Tensor\u001b[39m|\u001b[39m\u001b[39mNone\u001b[39;00m]:\n\u001b[0;32m--> 153\u001b[0m     y_affinity_pred, y_property_pred, coords \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(data\u001b[39m=\u001b[39;49mdata)\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m y_affinity_pred, y_property_pred, coords\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/gmsl/model.py:194\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    192\u001b[0m         channel_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_attr(data\u001b[39m.\u001b[39mresidue_elements\u001b[39m.\u001b[39mlong())\n\u001b[1;32m    193\u001b[0m     edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_attr(data\u001b[39m.\u001b[39medge_relations\u001b[39m.\u001b[39mlong())\n\u001b[0;32m--> 194\u001b[0m     s, coords \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgnn(s, edge_list, pos, channel_attr, channel_weights, data\u001b[39m.\u001b[39;49medge_weights, edge_attr)\n\u001b[1;32m    195\u001b[0m     \u001b[39m# dist_info = torch.norm(coords[:, :, None] - coords[:, None, :], dim=-1, keepdim=False).view(coords.shape[0], -1)\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# s = s + self.coord_lin(dist_info)\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdymean\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/gmsl/basemodels/hemenet.py:109\u001b[0m, in \u001b[0;36mHemeNet.forward\u001b[0;34m(self, input, edge_list, coords, channel_attr, channel_weights, edge_weights, edge_attr, node_attr)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39m# ieconv_edge_feature = self.get_ieconv_edge_feature(coords, input, channel_weights, edge_list)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)):\n\u001b[1;32m    108\u001b[0m     \u001b[39m# edge message passing\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     node_hidden, coord_hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i](layer_input, edge_list, coord_input, channel_attr, channel_weights, \n\u001b[1;32m    110\u001b[0m         edge_weights, edge_attr\u001b[39m=\u001b[39;49medge_attr, node_attr\u001b[39m=\u001b[39;49mnode_attr)\n\u001b[1;32m    111\u001b[0m     \u001b[39m# ieconv layer\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[39m# if self.use_ieconv:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m#     node_hidden = node_hidden + self.ieconvs[i](layer_input, ieconv_edge_feature, edge_list, edge_weights)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     node_hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(node_hidden)\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/gmsl/convs/hemenet.py:375\u001b[0m, in \u001b[0;36mAM_EGCL.forward\u001b[0;34m(self, h, edge_list, coords, channel_attr, channel_weights, edge_weights, edge_attr, node_attr)\u001b[0m\n\u001b[1;32m    373\u001b[0m num_nodes \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    374\u001b[0m relation \u001b[39m=\u001b[39m edge_list[:, \u001b[39m2\u001b[39m]\n\u001b[0;32m--> 375\u001b[0m node_message, coord_message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(h, edge_list, coords, channel_attr, channel_weights, edge_attr,\n\u001b[1;32m    376\u001b[0m                                            node_attr)\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39misnan(node_message)\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misnan(coord_message)\u001b[39m.\u001b[39many():\n\u001b[1;32m    378\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWrong output\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/gmsl/convs/hemenet.py:303\u001b[0m, in \u001b[0;36mAM_EGCL.message\u001b[0;34m(self, h, edge_list, coords, channel_attr, channel_weights, edge_attr, node_attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m edge_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoord_mlp(node_message)  \u001b[39m# [|E|, n_channel]\u001b[39;00m\n\u001b[1;32m    301\u001b[0m channel_sum \u001b[39m=\u001b[39m (channel_weights \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m pooled_edge_feat \u001b[39m=\u001b[39m RollerPooling(n_channel, edge_feat\u001b[39m.\u001b[39;49mdevice, edge_feat\u001b[39m.\u001b[39;49mdtype)(edge_feat, channel_sum[target])\n\u001b[1;32m    304\u001b[0m coord_message \u001b[39m=\u001b[39m coord_diff \u001b[39m*\u001b[39m pooled_edge_feat  \u001b[39m# [n_edge, n_channel, d]\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39misnan(node_message)\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misnan(coord_message)\u001b[39m.\u001b[39many():\n",
      "File \u001b[0;32m~/mambaforge/envs/gmsl_0928/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Research/DrugDD/GMSL_lite/GMSL/gmsl/convs/hemenet.py:171\u001b[0m, in \u001b[0;36mRollerPooling.forward\u001b[0;34m(self, hidden, target_size)\u001b[0m\n\u001b[1;32m    169\u001b[0m pool_mat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_matrix[target_size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]  \u001b[39m# [n_edges, n_channel, n_channel]\u001b[39;00m\n\u001b[1;32m    170\u001b[0m hidden \u001b[39m=\u001b[39m hidden\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# [n_edges, n_channel, 1]\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbmm(pool_mat, hidden)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [24520, 14] but got: [24520, 1]."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import wandb\n",
    "import torch\n",
    "import json\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from utils.task_models import MultiTaskModel, PropertyModel, AffinityModel\n",
    "from utils.datamodule import GMSLDataModule\n",
    "\n",
    "try:\n",
    "    TEST_DIR = osp.join(osp.dirname(osp.realpath(__file__)), \"tests\")\n",
    "except NameError:\n",
    "    TEST_DIR = \"./tests\"\n",
    "\n",
    "if not osp.exists(TEST_DIR):\n",
    "    os.makedirs(TEST_DIR)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # torch.multiprocessing.set_start_method('forkserver')\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    # args = get_argparse()\n",
    "    # device = args.device\n",
    "    device = [2]\n",
    "    wandb_logger = None\n",
    "        \n",
    "    # if args.model_args['task'] == 'multi':\n",
    "    #     model_cls = MultiTaskModel\n",
    "    # elif args.model_args['task'] in ['ec', 'go', 'mf', 'bp', 'cc']:\n",
    "    #     model_cls = PropertyModel\n",
    "    # elif args.model_args['task'] == 'affinity':\n",
    "    #     model_cls = AffinityModel\n",
    "    \n",
    "    model_cls = MultiTaskModel\n",
    "    # if args.test_name is not None:\n",
    "    #     model_dir = osp.join(TEST_DIR, args.test_name)\n",
    "    # else:\n",
    "    current_names = os.listdir(TEST_DIR)\n",
    "    unamed_exps = [i[4:] for i in current_names if 'test' in i]\n",
    "    if len(unamed_exps) > 0:\n",
    "        largest = sorted(unamed_exps, key=int)\n",
    "        current_num = str(int(largest[-1]) + 1)\n",
    "    else:\n",
    "        current_num = str(1)\n",
    "    current_exp = 'test' + current_num\n",
    "    model_dir = osp.join(TEST_DIR, current_exp)\n",
    "    if not osp.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    datamodule = GMSLDataModule(\n",
    "        batch_size=8,\n",
    "        num_workers=4,\n",
    "        train_split='train_all',\n",
    "        val_split='val',\n",
    "        test_split='test',\n",
    "        cache_dir='./datasets/MultiTask_c03_id09/graphs_new/hetero_alphaonly_forhemenet_knn5_spatial4.5_sequential2',\n",
    "        device='cuda' if device != 'cpu' else 'cpu',\n",
    "        seed=817,\n",
    "        task='multi'\n",
    "    )\n",
    "\n",
    "    model = model_cls.load_from_checkpoint(checkpoint_path='./models/hemenet_vallina/lightning_logs/version_18/checkpoints/last.ckpt', \n",
    "                                            hyp_path='./models/hemenet_vallina/lightning_logs/version_18/hparams.yaml',\n",
    "                                            map_location=None,\n",
    "                                           )\n",
    "    print(\n",
    "        f\"Model consists of {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable params.\"\n",
    "        )\n",
    "    for name, parameter in model.named_parameters():\n",
    "        print(name)\n",
    "    trainer = pl.Trainer(devices=device if device != \"cpu\" else None,\n",
    "            accelerator=\"gpu\" if device != \"cpu\" else \"cpu\",)\n",
    "    start_time = datetime.now()\n",
    "    trainer.test(model=model, ckpt_path='./models/hemenet_vallina/lightning_logs/version_18/checkpoints/last.ckpt', dataloaders=datamodule, verbose=True)\n",
    "    end_time = datetime.now()\n",
    "    time_diff = end_time - start_time\n",
    "    print(f\"Testing time: {time_diff}\")\n",
    "    # Output the testing result\n",
    "    res = model.res\n",
    "    # with open(os.path.join(model_dir, \"res.json\"), \"w\") as f:\n",
    "    #     json.dump(res, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
