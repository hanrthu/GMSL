{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "torch.Size([50, 16]) torch.Size([50, 16]) torch.Size([50])\n",
      "Calulating...\n",
      "torch.Size([50, 64]) torch.Size([50, 3])\n",
      "torch.Size([50, 1])\n",
      "It's my turn\n",
      "torch.Size([50, 64]) torch.Size([50, 3]) torch.Size([50])\n",
      "Done\n",
      "tensor([[-0.2349, -0.1054,  0.0346,  ..., -0.0755,  0.0426, -0.0114],\n",
      "        [-0.0837, -0.3273,  0.0299,  ..., -0.1072,  0.1049, -0.2252],\n",
      "        [-0.2218, -0.2731,  0.1572,  ..., -0.1133,  0.1486, -0.1403],\n",
      "        ...,\n",
      "        [-0.1854, -0.1367,  0.1585,  ...,  0.0404, -0.0164, -0.1617],\n",
      "        [-0.0670, -0.0375,  0.2003,  ..., -0.1988,  0.1194, -0.0788],\n",
      "        [-0.1002, -0.3127,  0.1781,  ..., -0.0506, -0.1033, -0.1486]],\n",
      "       grad_fn=<AddmmBackward0>) tensor([[ 0.3178,  1.0815,  0.8918],\n",
      "        [ 0.6076,  1.1006, -1.5017],\n",
      "        [ 0.9798,  0.7401,  0.8962],\n",
      "        [-0.9316,  0.2238,  0.6606],\n",
      "        [-2.3515, -0.4694, -1.3275],\n",
      "        [-0.4054,  1.7196, -0.9626],\n",
      "        [-0.4186, -0.2232,  0.8788],\n",
      "        [-0.0943, -0.1446,  0.6532],\n",
      "        [ 0.0376, -0.2009,  2.7853],\n",
      "        [-1.2915, -2.1900, -0.3624],\n",
      "        [ 0.8147,  0.8713,  1.2639],\n",
      "        [ 1.4882,  0.1005, -1.0328],\n",
      "        [-1.1146,  0.2028, -0.1393],\n",
      "        [ 2.1323, -1.9575,  0.2716],\n",
      "        [-0.3287, -1.4604, -2.4365],\n",
      "        [-0.8921,  1.2984,  0.0747],\n",
      "        [ 0.4837, -0.5264, -0.1115],\n",
      "        [-0.7494,  1.1758, -0.9992],\n",
      "        [-0.2802, -1.2112, -1.0258],\n",
      "        [ 0.3044,  1.1057,  0.0505],\n",
      "        [-0.3680, -0.2176, -0.5543],\n",
      "        [ 0.1786, -0.3146, -1.4068],\n",
      "        [-1.6468,  0.7364, -0.1768],\n",
      "        [ 1.0470,  0.9361, -1.6264],\n",
      "        [ 0.2097, -0.0322, -0.6895],\n",
      "        [-0.3115,  0.6481,  0.2811],\n",
      "        [-0.0848,  0.2559, -1.1555],\n",
      "        [ 3.3123,  0.6395, -0.5759],\n",
      "        [ 0.9039,  0.3959, -1.5222],\n",
      "        [-1.0898,  0.7877,  0.2327],\n",
      "        [-0.8578, -0.6258, -1.3618],\n",
      "        [-0.0436,  0.2000, -2.3423],\n",
      "        [ 0.6833, -1.0566,  1.0781],\n",
      "        [-0.0210, -0.7753, -0.5618],\n",
      "        [ 0.3021,  0.1903, -0.2056],\n",
      "        [-0.5093,  0.6982,  1.4505],\n",
      "        [-1.0738,  0.2457,  1.4670],\n",
      "        [ 1.1038, -0.5097,  1.0035],\n",
      "        [-0.2562, -0.2316,  1.1371],\n",
      "        [-0.0343, -0.4697, -0.6420],\n",
      "        [-2.3009,  1.9255,  0.8233],\n",
      "        [ 0.7044, -0.0746, -0.7368],\n",
      "        [-1.1887, -0.5000, -0.2675],\n",
      "        [-0.4506,  0.3241,  1.0180],\n",
      "        [ 0.6830, -0.8861,  0.2590],\n",
      "        [ 0.2055, -0.6950, -0.0852],\n",
      "        [-0.3643, -0.6821,  1.2202],\n",
      "        [-1.2446, -0.1204, -0.1348],\n",
      "        [ 1.2192, -0.2744,  1.3648],\n",
      "        [ 0.3810,  0.6345, -1.3044],\n",
      "        [-1.7673,  0.7980,  0.0313],\n",
      "        [-0.4390,  1.4516,  0.1588],\n",
      "        [-1.4848,  0.8751, -0.8393],\n",
      "        [-0.1416,  2.4825, -2.9847],\n",
      "        [-0.8284,  1.4022,  1.0161],\n",
      "        [-0.6819,  0.1055,  1.4921],\n",
      "        [-0.0976,  0.5627, -0.0100],\n",
      "        [ 1.1212, -0.7819, -0.6548],\n",
      "        [ 0.1693,  1.4106,  0.8723],\n",
      "        [-1.3542,  1.2614, -2.3911],\n",
      "        [-2.0055, -0.7902,  0.5769],\n",
      "        [ 2.3249, -0.2384, -0.3241],\n",
      "        [-0.3758, -0.7938, -0.5271],\n",
      "        [-0.1879, -0.5428, -1.7746],\n",
      "        [-1.2944,  0.8005,  1.1855],\n",
      "        [ 0.9590,  0.0074, -1.1711],\n",
      "        [ 0.8895, -0.7605, -1.5942],\n",
      "        [-0.0792, -0.4671,  0.3364],\n",
      "        [ 1.1009,  0.2561, -0.5293],\n",
      "        [ 0.8686, -0.0918,  1.4150],\n",
      "        [-0.3035,  0.9359, -1.0166],\n",
      "        [ 0.0872, -0.2233,  2.1246],\n",
      "        [-0.8493,  0.6651, -0.7175],\n",
      "        [ 1.2940, -0.5324, -0.9764],\n",
      "        [ 0.1568, -1.7488, -0.1428],\n",
      "        [-0.6224, -0.8060, -0.5417],\n",
      "        [ 0.1868, -1.2777, -0.1356],\n",
      "        [-0.5366,  0.9045,  2.1566],\n",
      "        [ 0.3112,  1.1504,  1.4344],\n",
      "        [-1.8054,  1.6361,  0.6300],\n",
      "        [-0.9135,  0.6343, -0.9626],\n",
      "        [-0.2502, -0.2352, -1.4716],\n",
      "        [-0.0360,  0.4916,  2.7223],\n",
      "        [ 0.3614, -0.8908, -1.0451],\n",
      "        [ 1.0841,  0.1528, -0.1668],\n",
      "        [ 1.8713,  0.1364,  1.0922],\n",
      "        [ 0.0352, -0.8324,  1.4372],\n",
      "        [ 0.8014, -0.6833,  0.8935],\n",
      "        [-0.1520, -0.6450,  0.4493],\n",
      "        [-1.4454, -0.4783,  0.8189],\n",
      "        [-2.0850, -0.2622, -0.1203],\n",
      "        [ 0.1378,  0.0658, -0.1712],\n",
      "        [-0.2013, -0.0128,  0.8718],\n",
      "        [ 0.3572,  0.4322, -1.3102],\n",
      "        [-0.3107, -0.0622, -2.0004],\n",
      "        [ 0.8355, -1.5066,  0.2056],\n",
      "        [ 0.0455,  0.8432,  1.3844],\n",
      "        [ 1.5850, -0.0711, -1.1228],\n",
      "        [ 2.1602, -1.1191,  0.2103],\n",
      "        [-0.7817,  0.7559,  1.3881]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Optional\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_scatter import scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class EGCL(MessagePassing):\n",
    "    def __init__(self,\n",
    "        in_dims: Tuple[int, Optional[int]],\n",
    "        out_dims: Tuple[int, Optional[int]],\n",
    "        hid_dims: int,\n",
    "        num_radial: int,\n",
    "        cutoff: float,\n",
    "        eps: float = 1e-6,\n",
    "        edges_in_df: int = 0,\n",
    "        has_v_in: bool = True,\n",
    "        basis: str = \"bessel\",\n",
    "        vector_aggr: str = \"mean\"):\n",
    "        super(EGCL, self).__init__(node_dim=0, aggr=None, flow=\"source_to_target\")\n",
    "        self.vector_aggr = vector_aggr\n",
    "        self.in_dims = in_dims\n",
    "        self.si, self.vi = in_dims\n",
    "        self.out_dims = out_dims\n",
    "        self.so, self.vo = out_dims\n",
    "        self.has_v_in = has_v_in\n",
    "        act_fn = nn.ReLU()\n",
    "        print(2*self.si + num_radial + edges_in_df)\n",
    "        self.phi_m = nn.Sequential(\n",
    "            nn.Linear(2*self.si+num_radial+edges_in_df, hid_dims),\n",
    "            act_fn,\n",
    "            nn.Linear(hid_dims, hid_dims)\n",
    "            )\n",
    "        self.phi_x = nn.Sequential(\n",
    "            nn.Linear(hid_dims, hid_dims),\n",
    "            act_fn,\n",
    "            nn.Linear(hid_dims,1,bias=False)\n",
    "        )\n",
    "        self.phi_h = nn.Sequential(\n",
    "            nn.Linear(self.si+hid_dims, hid_dims),\n",
    "            act_fn,\n",
    "            nn.Linear(hid_dims, self.so)\n",
    "        )\n",
    "    def aggregate(self, inputs: Tuple[Tensor, Tensor], index: Tensor, dim_size: Optional[int] = None) -> Tuple[Tensor, Tensor]:\n",
    "        print(\"It's my turn\")\n",
    "        print(inputs[0].shape, inputs[1].shape, index.shape)\n",
    "        ms = scatter(inputs[0], index=index, dim=0, dim_size=dim_size, reduce=\"sum\")\n",
    "        mv = scatter(inputs[1], index=index, dim=0, dim_size=dim_size, reduce=\"mean\")\n",
    "        print(\"Done\")\n",
    "        return ms, mv\n",
    "    def message(\n",
    "            self,\n",
    "            s_i: Tensor, \n",
    "            s_j: Tensor, \n",
    "            v_i: Tensor, \n",
    "            v_j: Tensor,\n",
    "            d: Tensor,\n",
    "            r: Tensor,\n",
    "        ) -> Tensor:\n",
    "        print(s_i.shape, s_j.shape, d.shape)\n",
    "        dist = torch.pow(d, 2).unsqueeze(-1)\n",
    "        a_ij = torch.cat([s_i, s_j, dist], dim=-1)\n",
    "        ms_j = self.phi_m(a_ij)\n",
    "        # 得到 X_j - X_i\n",
    "        # print(\"V_j:\", v_j)\n",
    "        rel_pos = v_i - v_j\n",
    "        print(\"Calulating...\")\n",
    "        # print(((v_j - v_i - (d.unsqueeze(-1) * r)) < 1e-2))\n",
    "        assert ((v_j - v_i - (d.unsqueeze(-1) * r)) < 1e-3).all()\n",
    "        print(ms_j.shape, rel_pos.shape)\n",
    "        print(self.phi_x(ms_j).shape)\n",
    "        mv_j = rel_pos * self.phi_x(ms_j)\n",
    "        # print(\"Hello!\")\n",
    "        return ms_j, mv_j\n",
    "    def forward(\n",
    "        self,   \n",
    "        x: Tuple[Tensor, Tensor],\n",
    "        edge_index: Tensor,\n",
    "        edge_attr: Tuple[Tensor, Tensor]):\n",
    "        s, v = x\n",
    "        # r 是相对的方向，单位向量\n",
    "        d, r = edge_attr\n",
    "        ms, mv = self.propagate(\n",
    "            edge_index=edge_index,\n",
    "            dim_size = s.size(0),\n",
    "            s=s,\n",
    "            v=v,\n",
    "            d=d,\n",
    "            r=r\n",
    "        )\n",
    "        \n",
    "        s = self.phi_h(torch.cat([s, ms], dim=-1))\n",
    "        v = v + mv\n",
    "        print(s, v)\n",
    "\n",
    "model = EGCL((16,3), (128,128), 64, 1, 6)\n",
    "nodes = torch.randn((100,16))\n",
    "pos = torch.randn((100,3))\n",
    "edge_index = torch.randint(0, 99, size=(2,50))\n",
    "rel_pos = pos[edge_index[0]] - pos[edge_index[1]]\n",
    "dist = torch.pow(rel_pos, 2).sum(-1).sqrt()\n",
    "# print(\"Pos_j:\", pos[edge_index[0]])\n",
    "r = F.normalize(rel_pos, dim=-1, eps=1e-6)\n",
    "# print((rel_pos-(dist.unsqueeze(-1)*r) < 1e-3).all())\n",
    "edge_attr = (dist, r)\n",
    "x = (nodes, pos)\n",
    "model(x, edge_index, edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method test.print of <__main__.test object at 0x7f3c08232790>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test(object):\n",
    "    def __init__(self) -> None:\n",
    "        self._weight = \"123\"\n",
    "    def print(self):\n",
    "        print(self.weight)\n",
    "        \n",
    "a = test()\n",
    "a.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 300) range(0, 300) range(0, 299) range(1, 300)\n",
      "range(0, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = range(300)\n",
    "b = a[:]\n",
    "c = a[:-1]\n",
    "d = a[1:]\n",
    "print(a,b,c,d)        \n",
    "print(a)\n",
    "print(range(10)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0579,  0.1234,  0.6805,  ..., -0.1826,  0.8181,  0.3417],\n",
      "        [-0.0579,  0.1234,  0.6805,  ..., -0.1826,  0.8181,  0.3417],\n",
      "        [-0.0579,  0.1234,  0.6805,  ..., -0.1826,  0.8181,  0.3417],\n",
      "        ...,\n",
      "        [-0.0579,  0.1234,  0.6805,  ..., -0.1826,  0.8181,  0.3417],\n",
      "        [-0.0579,  0.1234,  0.6805,  ..., -0.1826,  0.8181,  0.3417],\n",
      "        [-0.0579,  0.1234,  0.6805,  ..., -0.1826,  0.8181,  0.3417]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "linear = nn.Linear(21,100)\n",
    "x = torch.ones(100,21)\n",
    "\n",
    "print(linear(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqgat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
