{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "with codecs.open('../data/HomologyTAPE/pdb_chain_scop_uniprot.tsv', encoding='utf-8') as f:\n",
    "    for row in csv.DictReader(f, skipinitialspace=True, delimiter='\\t'):\n",
    "        rows.append(row)\n",
    "print(len(rows))\n",
    "print(rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dic = {}\n",
    "for row in rows:\n",
    "    fold_dic[row['SCOP_ID']] = {}\n",
    "    fold_dic[row['SCOP_ID']]['PDB-chain'] = row['PDB'].upper() + '-' + row['CHAIN']\n",
    "    fold_dic[row['SCOP_ID']]['uniprot'] = row['SP_PRIMARY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dic['d101ma_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HomologyTAPE/test_fold.txt') as f:\n",
    "    test_file_lines = f.readlines()\n",
    "test_lines = {}\n",
    "test_pdb = {}\n",
    "failed_test_scop = []\n",
    "for line in test_file_lines:\n",
    "    data = line.split('\\t')\n",
    "    data = [d.strip() for d in data]\n",
    "    test_lines[data[0]] = data[-1]\n",
    "    fold_all.append(data[0])\n",
    "    try:\n",
    "        if fold_dic[data[0]]['PDB-chain'] not in test_pdb.keys():\n",
    "            test_pdb[fold_dic[data[0]]['PDB-chain']] = []\n",
    "        test_pdb[fold_dic[data[0]]['PDB-chain']].append(data[-1])\n",
    "    except:\n",
    "        failed_test_scop.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HomologyTAPE/training.txt') as f:\n",
    "    train_file_lines = f.readlines()\n",
    "train_lines = {}\n",
    "train_pdb = {}\n",
    "failed_train_scop = []\n",
    "for line in train_file_lines:\n",
    "    data = line.split('\\t')\n",
    "    data = [d.strip() for d in data]\n",
    "    train_lines[data[0]] = data[-1]\n",
    "    fold_all.append(data[0])\n",
    "    try:\n",
    "        if fold_dic[data[0]]['PDB-chain'] not in train_pdb.keys():\n",
    "            train_pdb[fold_dic[data[0]]['PDB-chain']] = []\n",
    "        train_pdb[fold_dic[data[0]]['PDB-chain']].append(data[-1])\n",
    "    except:\n",
    "        failed_train_scop.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HomologyTAPE/validation.txt') as f:\n",
    "    val_file_lines = f.readlines()\n",
    "val_lines = {}\n",
    "val_pdb = {}\n",
    "failed_val_scop = []\n",
    "for line in val_file_lines:\n",
    "    data = line.split('\\t')\n",
    "    data = [d.strip() for d in data]\n",
    "    val_lines[data[0]] = data[-1]\n",
    "    fold_all.append(data[0])\n",
    "    try:\n",
    "        if fold_dic[data[0]]['PDB-chain'] not in val_pdb.keys():\n",
    "            val_pdb[fold_dic[data[0]]['PDB-chain']] = []\n",
    "        val_pdb[fold_dic[data[0]]['PDB-chain']].append(data[-1])\n",
    "    except:\n",
    "        failed_val_scop.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dic['d1ysya1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_pdb.items():\n",
    "    test_pdb[key] = list(set(value))\n",
    "for key, value in train_pdb.items():\n",
    "    train_pdb[key] = list(set(value))\n",
    "for key, value in val_pdb.items():\n",
    "    val_pdb[key] = list(set(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_file_lines))\n",
    "print(len(train_file_lines))\n",
    "print(len(val_file_lines))\n",
    "print(len(failed_test_scop))\n",
    "print(len(failed_train_scop))\n",
    "print(len(failed_val_scop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_pdb))\n",
    "print(len(train_pdb))\n",
    "print(len(val_pdb))\n",
    "print(len(test_pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pdb = list(test_pdb.keys()) + list(train_pdb.keys()) + list(val_pdb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pdb = [pdb[:4] for pdb in all_pdb]\n",
    "print(len(all_pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "no_download = []\n",
    "with open('../data/HomologyTAPE/all_download.json') as f:\n",
    "    download_pdb = json.load(f)\n",
    "with open('../data/HomologyTAPE/download_pdb.json') as f:\n",
    "    download_fold = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_fold = [i.upper() for i in download_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdb in tqdm(all_pdb):\n",
    "    if pdb not in download_pdb:\n",
    "        no_download.append(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_chains = list(test_pdb.keys()) + list(train_pdb.keys()) + list(val_pdb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/EnzymeCommission/nrPDB-EC_annot_copy.tsv') as f:\n",
    "    ec_lines = f.readlines()\n",
    "with open('../data/GeneOntology/nrPDB-GO_annot.tsv') as f:\n",
    "    go_lines = f.readlines()\n",
    "download_chains = []\n",
    "download_ec_chains = [ec.split('\\t')[0] for ec in ec_lines[1:]]\n",
    "download_go_chains = [ec.split('\\t')[0] for ec in go_lines[12:]]\n",
    "download_chains = download_ec_chains + download_go_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "download_fold = os.listdir('../data/HomologyTAPE/all/')\n",
    "download_fold = [i.split('.')[0] for i in download_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_fold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_chains = list(set(download_chains))\n",
    "need_download = []\n",
    "for pdb in tqdm(pdb_chains):\n",
    "    if pdb not in download_chains and pdb[:4] not in download_pdb and pdb[:4] not in download_fold:\n",
    "        need_download.append(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(need_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_download = [pdb[:4].lower() for pdb in need_download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(need_download)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "downloaded = os.listdir('../data/HomologyTAPE/all')\n",
    "downloaded = [pdb[:4].lower() for pdb in downloaded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(downloaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_d = []\n",
    "for pdb in need_download:\n",
    "    if pdb not in downloaded:\n",
    "        n_d.append(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_d = list(set(n_d))\n",
    "print(len(n_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_d = []\n",
    "for scop in fold_all:\n",
    "    if scop[-1] != '_':\n",
    "        n_d.append(scop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_d)\n",
    "n_d = list(set(n_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/8113 [00:24<54:17:24, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot download: d2h3la1\n"
     ]
    }
   ],
   "source": [
    "failed = 0\n",
    "root_dir = '../data/HomologyTAPE/'\n",
    "idx = 0\n",
    "download_pdb = []\n",
    "failed_pdb = []\n",
    "for scopid in tqdm(n_d):\n",
    "    \n",
    "    # if idx == 10:\n",
    "    #     break\n",
    "    try:\n",
    "        \n",
    "        url = 'https://scop.berkeley.edu/downloads/pdbstyle/pdbstyle-1.75/'+scopid[2:4] + '/'+ scopid + '.ent'\n",
    "        # print(url)\n",
    "        urlretrieve(url, root_dir +'all/' + scopid + '.pdb')\n",
    "        download_pdb.append(scopid.lower())\n",
    "    except:\n",
    "        print(\"cannot download:\", scopid)\n",
    "        failed += 1\n",
    "        failed_pdb.append(scopid.lower())\n",
    "    idx += 1\n",
    "with open('../data/HomologyTAPE/download_scopid.json', 'w') as f:\n",
    "    json.dump(download_pdb, f)\n",
    "with open('../data/HomologyTAPE/failed_scopid.json', 'w') as f:\n",
    "    json.dump(failed_pdb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "failed = 0\n",
    "root_dir = '../data/HomologyTAPE/'\n",
    "idx = 0\n",
    "# download_pdb = []\n",
    "# failed_pdb = []\n",
    "with open('../data/HomologyTAPE/failed_scopid.json', 'r') as f:\n",
    "    failed_pdb = json.load(f)\n",
    "for scopid in tqdm(n_d):\n",
    "    \n",
    "    # if idx == 10:\n",
    "    #     break\n",
    "    try:\n",
    "        \n",
    "        url = 'https://scop.berkeley.edu/downloads/pdbstyle/pdbstyle-1.75/'+scopid[2:4] + '/'+ scopid + '.ent'\n",
    "        # print(url)\n",
    "        urlretrieve(url, root_dir +'all/' + scopid + '.pdb')\n",
    "        download_pdb.append(scopid.lower())\n",
    "    except:\n",
    "        print(\"cannot download:\", scopid)\n",
    "        failed += 1\n",
    "        failed_pdb.append(scopid.lower())\n",
    "    idx += 1\n",
    "with open('../data/HomologyTAPE/download_scopid_1.json', 'w') as f:\n",
    "    json.dump(download_pdb, f)\n",
    "with open('../data/HomologyTAPE/failed_scopid_1.json', 'w') as f:\n",
    "    json.dump(failed_pdb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"../data/HomologyTAPE/d2gyco1.hdf5\",\"r\")\n",
    "print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['amino_chains'][()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reptile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
