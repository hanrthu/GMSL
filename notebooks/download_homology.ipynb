{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104840\n",
      "{'PDB': '101m', 'CHAIN': 'A', 'SP_PRIMARY': 'P02185', 'SUNID': '15125', 'SCOP_ID': 'd101ma_'}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "with codecs.open('../data/HomologyTAPE/pdb_chain_scop_uniprot.tsv', encoding='utf-8') as f:\n",
    "    for row in csv.DictReader(f, skipinitialspace=True, delimiter='\\t'):\n",
    "        rows.append(row)\n",
    "print(len(rows))\n",
    "print(rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dic = {}\n",
    "for row in rows:\n",
    "    fold_dic[row['SCOP_ID']] = {}\n",
    "    fold_dic[row['SCOP_ID']]['PDB-chain'] = row['PDB'].upper() + '-' + row['CHAIN']\n",
    "    fold_dic[row['SCOP_ID']]['uniprot'] = row['SP_PRIMARY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PDB-chain': '101M-A', 'uniprot': 'P02185'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_dic['d101ma_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HomologyTAPE/test_fold.txt') as f:\n",
    "    test_file_lines = f.readlines()\n",
    "test_lines = {}\n",
    "test_pdb = {}\n",
    "failed_test_scop = []\n",
    "for line in test_file_lines:\n",
    "    data = line.split('\\t')\n",
    "    data = [d.strip() for d in data]\n",
    "    test_lines[data[0]] = data[-1]\n",
    "    try:\n",
    "        if fold_dic[data[0]]['PDB-chain'] not in test_pdb.keys():\n",
    "            test_pdb[fold_dic[data[0]]['PDB-chain']] = []\n",
    "        test_pdb[fold_dic[data[0]]['PDB-chain']].append(data[-1])\n",
    "    except:\n",
    "        failed_test_scop.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HomologyTAPE/training.txt') as f:\n",
    "    train_file_lines = f.readlines()\n",
    "train_lines = {}\n",
    "train_pdb = {}\n",
    "failed_train_scop = []\n",
    "for line in train_file_lines:\n",
    "    data = line.split('\\t')\n",
    "    data = [d.strip() for d in data]\n",
    "    train_lines[data[0]] = data[-1]\n",
    "    try:\n",
    "        if fold_dic[data[0]]['PDB-chain'] not in train_pdb.keys():\n",
    "            train_pdb[fold_dic[data[0]]['PDB-chain']] = []\n",
    "        train_pdb[fold_dic[data[0]]['PDB-chain']].append(data[-1])\n",
    "    except:\n",
    "        failed_train_scop.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/HomologyTAPE/validation.txt') as f:\n",
    "    val_file_lines = f.readlines()\n",
    "val_lines = {}\n",
    "val_pdb = {}\n",
    "failed_val_scop = []\n",
    "for line in val_file_lines:\n",
    "    data = line.split('\\t')\n",
    "    data = [d.strip() for d in data]\n",
    "    val_lines[data[0]] = data[-1]\n",
    "    try:\n",
    "        if fold_dic[data[0]]['PDB-chain'] not in val_pdb.keys():\n",
    "            val_pdb[fold_dic[data[0]]['PDB-chain']] = []\n",
    "        val_pdb[fold_dic[data[0]]['PDB-chain']].append(data[-1])\n",
    "    except:\n",
    "        failed_val_scop.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PDB-chain': '1YSY-A', 'uniprot': 'P0C6X7'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_dic['d1ysya1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_pdb.items():\n",
    "    test_pdb[key] = list(set(value))\n",
    "for key, value in train_pdb.items():\n",
    "    train_pdb[key] = list(set(value))\n",
    "for key, value in val_pdb.items():\n",
    "    val_pdb[key] = list(set(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718\n",
      "12312\n",
      "736\n",
      "17\n",
      "550\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(test_file_lines))\n",
    "print(len(train_file_lines))\n",
    "print(len(val_file_lines))\n",
    "print(len(failed_test_scop))\n",
    "print(len(failed_train_scop))\n",
    "print(len(failed_val_scop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667\n",
      "9952\n",
      "706\n",
      "667\n"
     ]
    }
   ],
   "source": [
    "print(len(test_pdb))\n",
    "print(len(train_pdb))\n",
    "print(len(val_pdb))\n",
    "print(len(test_pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pdb = list(test_pdb.keys()) + list(train_pdb.keys()) + list(val_pdb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325\n"
     ]
    }
   ],
   "source": [
    "all_pdb = [pdb[:4] for pdb in all_pdb]\n",
    "print(len(all_pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "no_download = []\n",
    "with open('../data/HomologyTAPE/all_download.json') as f:\n",
    "    download_pdb = json.load(f)\n",
    "with open('../data/HomologyTAPE/download_pdb.json') as f:\n",
    "    download_fold = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_fold = [i.upper() for i in download_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 171/11325 [00:00<00:32, 340.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11325/11325 [00:48<00:00, 231.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for pdb in tqdm(all_pdb):\n",
    "    if pdb not in download_pdb:\n",
    "        no_download.append(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_chains = list(test_pdb.keys()) + list(train_pdb.keys()) + list(val_pdb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/EnzymeCommission/nrPDB-EC_annot_copy.tsv') as f:\n",
    "    ec_lines = f.readlines()\n",
    "with open('../data/GeneOntology/nrPDB-GO_annot.tsv') as f:\n",
    "    go_lines = f.readlines()\n",
    "download_chains = []\n",
    "download_ec_chains = [ec.split('\\t')[0] for ec in ec_lines[1:]]\n",
    "download_go_chains = [ec.split('\\t')[0] for ec in go_lines[12:]]\n",
    "download_chains = download_ec_chains + download_go_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "download_fold = os.listdir('../data/HomologyTAPE/all/')\n",
    "download_fold = [i.split('.')[0] for i in download_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2QN6'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_fold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/11325 [00:00<01:01, 182.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11325/11325 [01:03<00:00, 178.69it/s]\n"
     ]
    }
   ],
   "source": [
    "download_chains = list(set(download_chains))\n",
    "need_download = []\n",
    "for pdb in tqdm(pdb_chains):\n",
    "    if pdb not in download_chains and pdb[:4] not in download_pdb and pdb[:4] not in download_fold:\n",
    "        need_download.append(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(need_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_download = [pdb[:4].lower() for pdb in need_download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9273"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(need_download)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "downloaded = os.listdir('../data/HomologyTAPE/all')\n",
    "downloaded = [pdb[:4].lower() for pdb in downloaded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6556"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(downloaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_d = []\n",
    "for pdb in need_download:\n",
    "    if pdb not in downloaded:\n",
    "        n_d.append(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717\n"
     ]
    }
   ],
   "source": [
    "n_d = list(set(n_d))\n",
    "print(len(n_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2916 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2916/2916 [57:56<00:00,  1.19s/it] \n"
     ]
    }
   ],
   "source": [
    "failed = 0\n",
    "root_dir = '../data/HomologyTAPE/'\n",
    "idx = 0\n",
    "download_pdb = downloaded\n",
    "failed_pdb = []\n",
    "for pdbid in tqdm(n_d):\n",
    "    \n",
    "    # if idx == 10:\n",
    "    #     break\n",
    "    try:\n",
    "        \n",
    "        url = 'https://ftp.wwpdb.org/pub/pdb/data/structures/divided/pdb/'+pdbid[1:3]+'/pdb' + pdbid + '.ent.gz'\n",
    "        # print(url)\n",
    "        urlretrieve(url, root_dir +'all/' + pdbid.upper() + '.pdb.gz')\n",
    "        download_pdb.append(pdbid.lower())\n",
    "    except:\n",
    "        print(\"cannot download:\", pdbid)\n",
    "        failed += 1\n",
    "        failed_pdb.append(pdbid.lower())\n",
    "    idx += 1\n",
    "with open('../data/HomologyTAPE/download_pdb.json', 'w') as f:\n",
    "    json.dump(download_pdb, f)\n",
    "with open('../data/HomologyTAPE/failed_pdb.json', 'w') as f:\n",
    "    json.dump(failed_pdb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['amino_chains', 'amino_neighs', 'amino_neighs_hb', 'amino_neighs_sindices', 'amino_neighs_sindices_hb', 'amino_pos', 'amino_types', 'atom_amino_id', 'atom_chain_ids', 'atom_chain_names', 'atom_names', 'atom_pos', 'atom_residue_id', 'atom_residue_names', 'atom_types', 'cov_bond_list', 'cov_bond_list_hb', 'cov_bond_list_sindices', 'cov_bond_list_sindices_hb', 'pos_center']>\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"../data/HomologyTAPE/d2gyco1.hdf5\",\"r\")\n",
    "print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['amino_chains'][()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reptile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
