{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for processing the dataset to form a new multi-task dataset with a unform labeling code\n",
    "# Datasets PDBBind(Protein-Ligand, Protein-Protein), EnzymeCommission, GeneOntology\n",
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cal_complex_all(json_dirs):\n",
    "    complex_list = []\n",
    "    for json_dir in json_dirs:\n",
    "        with open(json_dir, 'r') as f:\n",
    "            info_dict = json.load(f)\n",
    "        for i in info_dict:\n",
    "            if '-' in i:\n",
    "                id = i.split('-')[0].lower()\n",
    "            complex_list.append(id)\n",
    "    print(len(list(set(complex_list))))\n",
    "        \n",
    "\n",
    "def gen_train_test_ids(complex_dict, ec_dict, go_dict):\n",
    "    train_list = []\n",
    "    # print(complex_dict)\n",
    "    all_list = []\n",
    "    for k, v in complex_dict.items():\n",
    "        all_list.extend(v)\n",
    "    all_list = list(set(all_list))\n",
    "    for k, v in complex_dict.items():\n",
    "        # print(k, v)\n",
    "        # 由于每个蛋白可能有多个Uniprot，可以根据某一个Uniprot不在的情况找出训练集的样本\n",
    "        if k not in ec_dict or k not in go_dict:\n",
    "            train_list.extend(v)\n",
    "    #取反即可获得标注完整的数据集\n",
    "    test_list = [i for i in all_list if i not in train_list]\n",
    "    test_uniprots = []\n",
    "    for k, v in complex_dict.items():\n",
    "        for id in v:\n",
    "            if id in test_list and k not in test_uniprots:\n",
    "                test_uniprots.append(k)\n",
    "    # print(\"Uniprots:\", len(test_uniprots))\n",
    "    # print(\"Train:\", len(train_list), len(list(set(train_list))))\n",
    "    # print(\"Test:\", len(test_list), len(list(set(test_list))))\n",
    "    # print(\"All:\", len(list(set(test_list + train_list))))\n",
    "    # print(list(set(train_list)))\n",
    "    return list(set(train_list)), list(set(test_list)), list(set(test_uniprots))\n",
    "        \n",
    "            \n",
    "def gen_protein_property_uniprots(json_dir: str, single=True):\n",
    "    with open(json_dir, 'r') as f:\n",
    "        info_dict = json.load(f)\n",
    "    uniprot_dict = {} # 蛋白质 dictionary\n",
    "    print(len(info_dict))\n",
    "    if '7NS4-b' in info_dict.keys():\n",
    "        print('7NS4')\n",
    "    info_dict_new = {}\n",
    "    for k, v in info_dict.items():\n",
    "        if single:\n",
    "            if len(v) != 1:\n",
    "                continue\n",
    "            else:\n",
    "                uniprot_id = v[0]\n",
    "                info_dict_new[k] = [uniprot_id]   \n",
    "                # 只记录同一个uniprot id的所有pdb_id\n",
    "                if uniprot_id not in uniprot_dict:     \n",
    "                    uniprot_dict[uniprot_id] = k\n",
    "                # else:\n",
    "                #     uniprot_dict[uniprot_id].append(k)\n",
    "        else:\n",
    "            # Remove items whose uniprot ids are larger than 3 or equal zero.\n",
    "            if len(v) == 0 or len(v) > 3:\n",
    "                continue\n",
    "            else:\n",
    "                info_dict_new[k] = v\n",
    "                for uniprot_id in v:\n",
    "                    if uniprot_id not in uniprot_dict:\n",
    "                        uniprot_dict[uniprot_id] = [k]\n",
    "                    else:\n",
    "                        uniprot_dict[uniprot_id].append(k)\n",
    "    # print(\"Unitest:\", len(uniprot_dict), len(info_dict_new))\n",
    "    return uniprot_dict, info_dict_new\n",
    "    \n",
    "def save_dataset_info(dir, complex_list):\n",
    "    with open(dir, 'w') as f:\n",
    "        for complex in complex_list:\n",
    "            f.write(complex + '\\n')\n",
    "        f.close()\n",
    "\n",
    "def gen_ec_labels():\n",
    "    # root_dir = './data/EnzymeCommission/nrPDB-EC_annot.tsv'\n",
    "    root_dir = './data/EC/nrPDB-EC_annot.tsv'\n",
    "    download_pdb = './data/EC/download_pdb.json'\n",
    "    with open(root_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(download_pdb, 'r') as d:\n",
    "        download = json.load(d)\n",
    "    ec_classes = lines[1].strip().split('\\t')\n",
    "    label_dict = {}\n",
    "    pdb_annot_dict = {}\n",
    "    label_id = 0\n",
    "    for label in ec_classes:\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = label_id\n",
    "            label_id += 1\n",
    "    cnt = 0\n",
    "    for item in lines[3:]:\n",
    "        pdb_id, annotations = item.split('\\t')\n",
    "        annotations_list = annotations.strip().split(',')\n",
    "        pdb_annot_dict[pdb_id] = [label_dict[annot] for annot in annotations_list]\n",
    "    return pdb_annot_dict\n",
    "    # print(\"Number of classes in task {} is {}\".format('EnzymeCommission', label_id))\n",
    "\n",
    "# def get_full_annotation(go_uniprot_dict):\n",
    "#     root_dir = './datasets/GeneOntology/nrPDB-GO_annot.tsv'\n",
    "#     with open(root_dir, 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "#     go_classes_molecular_functions = lines[1].strip().split('\\t')\n",
    "#     go_classes_biological_process = lines[5].strip().split('\\t')\n",
    "#     go_classes_cellular_component = lines[9].strip().split('\\t')\n",
    "#     for k, v in go_uniprot_dict.items():\n",
    "        \n",
    "\n",
    "def gen_go_labels(go_uniprot_dict):\n",
    "    # root_dir = './data/GeneOntology/nrPDB-GO_annot.tsv'\n",
    "    root_dir = './data/GO/nrPDB-GO_annot.tsv'\n",
    "    \n",
    "    with open(root_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    go_classes_molecular_functions = lines[1].strip().split('\\t')\n",
    "    go_classes_biological_process = lines[5].strip().split('\\t')\n",
    "    go_classes_cellular_component = lines[9].strip().split('\\t')\n",
    "    \n",
    "    label_dict = {'molecular_functions':{}, 'biological_process':{}, 'cellular_component':{}}\n",
    "    pdb_annot_dict = {}\n",
    "    label_id_molecular = 0\n",
    "    label_id_biological = 0\n",
    "    label_id_cellular = 0\n",
    "    full_ids = []\n",
    "    full_uniprot_dict = {}\n",
    "    for label in go_classes_molecular_functions:\n",
    "        if label not in label_dict['molecular_functions']:\n",
    "            label_dict['molecular_functions'][label] = label_id_molecular\n",
    "            label_id_molecular += 1\n",
    "    for label in go_classes_biological_process:\n",
    "        if label not in label_dict['biological_process']:\n",
    "            label_dict['biological_process'][label] = label_id_biological\n",
    "            label_id_biological += 1\n",
    "    for label in go_classes_cellular_component:\n",
    "        if label not in label_dict['cellular_component']:\n",
    "            label_dict['cellular_component'][label] = label_id_cellular\n",
    "            label_id_cellular += 1\n",
    "    for item in tqdm(lines[13:]):\n",
    "        pdb_id, molecular, biological, cellular = item.split('\\t')\n",
    "        flag = False\n",
    "        # for go_uniprot_values in go_uniprot_dict.values():\n",
    "        #     if pdb_id in go_uniprot_values:\n",
    "        #         flag = True\n",
    "        #         break\n",
    "        if pdb_id in go_uniprot_dict.values():\n",
    "            if pdb_id == '3EWD-A':\n",
    "                print(molecular, biological, cellular)\n",
    "            molecular_list  = molecular.strip().split(',')\n",
    "            biological_list = biological.strip().split(',')\n",
    "            cellular_list = cellular.strip().split(',')\n",
    "            # print(molecular_list)\n",
    "            # 列表中会包含一些空的信息\n",
    "            pdb_annot_dict[pdb_id] = {'molecular_functions':[label_dict['molecular_functions'][annot] for annot in molecular_list if annot != ''],\n",
    "                                    'biological_process':[label_dict['biological_process'][annot] for annot in biological_list if annot != ''],\n",
    "                                    'cellular_component':[label_dict['cellular_component'][annot] for annot in cellular_list if annot != '']}\n",
    "            if pdb_annot_dict[pdb_id]['molecular_functions'] != [] and pdb_annot_dict[pdb_id]['biological_process'] != [] and pdb_annot_dict[pdb_id]['cellular_component'] != []:\n",
    "                full_ids.append(pdb_id)\n",
    "            if pdb_id == '6A12-A' or pdb_id == '3EWD-A':\n",
    "                print(pdb_annot_dict[pdb_id])\n",
    "    for k, v in go_uniprot_dict.items():\n",
    "        if v in full_ids:\n",
    "            full_uniprot_dict[k] = v\n",
    "    print(\"Number of classes in task {} is {}\".format('molecular_functions', label_id_molecular+1))\n",
    "    print(\"Number of classes in task {} is {}\".format('biological_process', label_id_biological+1))\n",
    "    print(\"Number of classes in task {} is {}\".format('cellular_component', label_id_cellular+1))\n",
    "    # print(pdb_annot_dict)\n",
    "    return pdb_annot_dict, full_uniprot_dict\n",
    "    # print(pdb_annot_dict)\n",
    "\n",
    "\n",
    "def gen_lba_labels():\n",
    "    root_dir = './data/PDBbind/refined-set/index/INDEX_general_PL_data.2020'\n",
    "    res = {}\n",
    "    with open(root_dir) as f:\n",
    "        for line in f:\n",
    "            if '#' in line:\n",
    "                continue\n",
    "            cont = line.strip().split()\n",
    "            if len(cont) < 5:\n",
    "                continue\n",
    "            code, pk = cont[0], cont[3]\n",
    "            res[code] = float(pk)\n",
    "    # print(\"LBA:\", len(res))\n",
    "    return res\n",
    "\n",
    "def gen_ppi_labels():\n",
    "    root_dir = './data/protein_protein/pp_affinity.xlsx'\n",
    "    pp_info = pd.read_excel(root_dir, header=1)\n",
    "    pdb_codes = pp_info['PDB code']\n",
    "    res = {}\n",
    "    for i, code in enumerate(pdb_codes):\n",
    "        res[code] = pp_info['pKd pKi pIC50'][i]\n",
    "    # print(\"PPI:\", len(res))\n",
    "    return res\n",
    "\n",
    "def gen_label(pdb_ids, ec_labels, go_labels, ppi_labels, lba_labels, ec_uniprot_dict, go_uniprot_dict, ec_info_dict, go_info_dict, pp_info_dict, pl_info_dict):\n",
    "    uniform_labels = {}\n",
    "    \n",
    "    for pdb_id in pdb_ids:\n",
    "        try:\n",
    "            if pdb_id[:4] == '7NS4':\n",
    "                print(pdb_id)\n",
    "            if '-' in pdb_id:\n",
    "                if pdb_id == '6A12-A':\n",
    "                    print('6A12-A')\n",
    "                    print(go_info_dict[pdb_id])\n",
    "                    # print(go_labels)\n",
    "                    print('6A12-A')\n",
    "                if pdb_id in ec_labels:\n",
    "                    uniprots = ec_info_dict[pdb_id]\n",
    "                    single_ec_label = [ec_labels[pdb_id]]\n",
    "                else:\n",
    "                    single_ec_label = [-1]\n",
    "                if pdb_id in go_labels:\n",
    "                    if pdb_id == '6A12-A':\n",
    "                        print(\"go 6A12-A\")\n",
    "                    uniprots = go_info_dict[pdb_id]\n",
    "                    single_go_label = [go_labels[pdb_id]]\n",
    "                else:\n",
    "                    single_go_label = [-1]\n",
    "            else:\n",
    "                single_ec_label = []\n",
    "                single_go_label = []\n",
    "                if pdb_id in pp_info_dict:\n",
    "                    uniprots = pp_info_dict[pdb_id]\n",
    "                elif pdb_id in pl_info_dict:\n",
    "                    uniprots = pl_info_dict[pdb_id]\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                for uniprot_id in uniprots:\n",
    "                    if uniprot_id in ec_uniprot_dict:\n",
    "                        ec_label = ec_labels[ec_uniprot_dict[uniprot_id]]\n",
    "                    else:\n",
    "                        ec_label = -1\n",
    "                    if uniprot_id in go_uniprot_dict:\n",
    "                        go_label = go_labels[go_uniprot_dict[uniprot_id]]\n",
    "                    else:\n",
    "                        go_label = -1\n",
    "                    single_ec_label.append(ec_label)\n",
    "                    single_go_label.append(go_label)\n",
    "            if pdb_id in ppi_labels:\n",
    "                ppi_label = ppi_labels[pdb_id]\n",
    "            else:\n",
    "                ppi_label = -1\n",
    "            if pdb_id in lba_labels:\n",
    "                lba_label = lba_labels[pdb_id]\n",
    "            else:\n",
    "                lba_label = -1\n",
    "            uniform_labels[pdb_id] = {\"uniprots\":uniprots, \"ec\": single_ec_label, \"go\": single_go_label, \"ppi\": ppi_label, \"lba\": lba_label}\n",
    "        except Exception as exp:\n",
    "            pass\n",
    "            # print(exp)\n",
    "            # print('pdbid:', pdb_id)\n",
    "    return uniform_labels\n",
    "    # print(uniform_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_reaction_labels():\n",
    "    root_dir = './data/ProtFunc/chain_functions.txt'\n",
    "    pdb_uniprot_dict = json.load(open('./output_info/reaction_uniprots.json'))\n",
    "    f = open(root_dir)\n",
    "    lines = f.readlines()\n",
    "    pdb_annot_dict = {}\n",
    "    for line in lines:\n",
    "        pdbid,label = line.split(',')\n",
    "        pdbid = pdbid.replace('.','-').upper()\n",
    "        if(pdbid in pdb_uniprot_dict.keys()):\n",
    "            uniprot_ids = pdb_uniprot_dict[pdbid]\n",
    "            pdb_annot_dict[pdbid] = [int(label.strip('\\n'))]\n",
    "    return pdb_annot_dict\n",
    "\n",
    "def gen_reaction_uniprots():\n",
    "    \"生成uniprot_dict, info_dict\"\n",
    "    input_json_dir = \"./output_info/enzyme_commission_new_uniprots.json\"\n",
    "    output_json_dir = \"./output_info/reaction_uniprots.json\"\n",
    "    all_uniprots_dict = json.load(open(input_json_dir))\n",
    "    new_uniprots_dict = {}\n",
    "    chain_function_file = open('./data/ProtFunc/chain_functions.txt','r')\n",
    "    for line in chain_function_file.readlines():\n",
    "        pdbid = line.split(',')[0]\n",
    "        pdbid = pdbid.replace('.','-').upper()\n",
    "        try:\n",
    "            new_uniprots_dict[pdbid] = all_uniprots_dict[pdbid]\n",
    "        except:\n",
    "            print(\"{} not found\".format(pdbid))\n",
    "    json.dump(new_uniprots_dict,open(output_json_dir,'w'))\n",
    "    return gen_protein_property_uniprots(output_json_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_test_ids_new(complex_dict,ec_dict,go_dict,reaction_dict):\n",
    "    train_list = []\n",
    "    # print(complex_dict)\n",
    "    all_list = []\n",
    "    for k, v in complex_dict.items():\n",
    "        all_list.extend(v) # k is uniprot id v is pdb ids\n",
    "    all_list = list(set(all_list))\n",
    "    for k, v in complex_dict.items():\n",
    "        # print(k, v)\n",
    "        # 由于每个蛋白可能有多个Uniprot，可以根据某一个Uniprot不在的情况找出训练集的样本\n",
    "        if k not in ec_dict or k not in go_dict or k not in reaction_dict:\n",
    "            train_list.extend(v) # train_list:哪些pdb_id中有uniprot缺少ec或者go标注\n",
    "    #取反即可获得标注完整的数据集\n",
    "    test_list = [i for i in all_list if i not in train_list] # test_list:哪些pdb_id中所有uniprot有完整的ec和go标注\n",
    "    test_uniprots = []\n",
    "    for k, v in complex_dict.items():\n",
    "        for id in v:\n",
    "            if id in test_list and k not in test_uniprots:\n",
    "                test_uniprots.append(k)\n",
    "    # print(\"Uniprots:\", len(test_uniprots))\n",
    "    # print(\"Train:\", len(train_list), len(list(set(train_list))))\n",
    "    # print(\"Test:\", len(test_list), len(list(set(test_list))))\n",
    "    # print(\"All:\", len(list(set(test_list + train_list))))\n",
    "    # print(list(set(train_list)))\n",
    "    return list(set(train_list)), list(set(test_list)), list(set(test_uniprots))\n",
    "\n",
    "def gen_label_new(pdb_ids, ec_labels, go_labels,reaction_labels, ppi_labels, lba_labels, ec_uniprot_dict, go_uniprot_dict,reaction_uniprot_dict, ec_info_dict, go_info_dict,reaction_info_dict, pp_info_dict, pl_info_dict):\n",
    "    uniform_labels = {}\n",
    "    for pdb_id in pdb_ids:\n",
    "        if '-' in pdb_id:\n",
    "            if pdb_id in ec_labels:\n",
    "                uniprots = ec_info_dict[pdb_id]\n",
    "                single_ec_label = [ec_labels[pdb_id]]\n",
    "            else:\n",
    "                single_ec_label = [-1]\n",
    "            if pdb_id in go_labels:\n",
    "                uniprots = go_info_dict[pdb_id]\n",
    "                single_go_label = [go_labels[pdb_id]]\n",
    "            else:\n",
    "                single_go_label = [-1]\n",
    "            if pdb_id in reaction_labels and pdb_id in reaction_info_dict:\n",
    "                uniprots = reaction_info_dict[pdb_id] \n",
    "                single_reaction_label = [reaction_labels[pdb_id]]\n",
    "            else:\n",
    "                single_reaction_label = [-1]\n",
    "                \n",
    "        else:\n",
    "            single_ec_label = []\n",
    "            single_go_label = []\n",
    "            single_reaction_label = []\n",
    "            if pdb_id in pp_info_dict:\n",
    "                uniprots = pp_info_dict[pdb_id]\n",
    "            elif pdb_id in pl_info_dict:\n",
    "                uniprots = pl_info_dict[pdb_id]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            for uniprot_id in uniprots:\n",
    "                if uniprot_id == '1A5H-A':\n",
    "                    print(uniprots, pdb_id)\n",
    "                if uniprot_id in ec_uniprot_dict:\n",
    "                    ec_label = ec_labels[ec_uniprot_dict[uniprot_id]]\n",
    "                else:\n",
    "                    ec_label = -1\n",
    "                if uniprot_id in go_uniprot_dict:\n",
    "                    go_label = go_labels[go_uniprot_dict[uniprot_id]]\n",
    "                else:\n",
    "                    go_label = -1\n",
    "                if uniprot_id in reaction_uniprot_dict:\n",
    "                    reaction_label = reaction_labels[reaction_uniprot_dict[uniprot_id]]\n",
    "                else:\n",
    "                    reaction_label = -1\n",
    "                single_ec_label.append(ec_label)\n",
    "                single_go_label.append(go_label)\n",
    "                single_reaction_label.append(reaction_label)\n",
    "        if pdb_id in ppi_labels:\n",
    "            ppi_label = ppi_labels[pdb_id]\n",
    "        else:\n",
    "            ppi_label = -1\n",
    "        if pdb_id in lba_labels:\n",
    "            lba_label = lba_labels[pdb_id]\n",
    "        else:\n",
    "            lba_label = -1\n",
    "        uniform_labels[pdb_id] = {\"uniprots\":uniprots, \"ec\": single_ec_label, \"go\": single_go_label, \"reaction\":single_reaction_label,\"ppi\": ppi_label, \"lba\": lba_label}\n",
    "    return uniform_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing original datasets to a multitask dataset\n",
      "152333\n",
      "7NS4\n",
      "284796\n",
      "7NS4\n",
      "2854\n",
      "5318\n",
      "Number of samples pl, pp, ec, go: 5208 2662 151946 284421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 228753/284795 [09:44<02:44, 341.57it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Start processing original datasets to a multitask dataset\")\n",
    "root_dir = './output_info/'\n",
    "# json_files = ['enzyme_commission_uniprots.json', 'gene_ontology_uniprots.json', 'protein_protein_uniprots.json', 'protein_ligand_uniprots.json']\n",
    "# json_files = ['ec_uniprots.json', 'gene_ontology_uniprots.json', 'protein_protein_uniprots.json', 'protein_ligand_uniprots.json']\n",
    "json_files = ['ec_uniprots.json', 'go_uniprots.json', 'protein_protein_uniprots.json', 'protein_ligand_uniprots.json']\n",
    "json_dirs = [os.path.join(root_dir, json_file) for json_file in json_files]\n",
    "# cal_complex_all(json_dirs)\n",
    "# uniprot_dict: {Uniprot id: [List of pdb ids]}\n",
    "# info_dict: {PDB id: [List of uniprot ids]}\n",
    "ec_uniprot_dict, ec_info_dict = gen_protein_property_uniprots(json_dirs[0])\n",
    "if '7OVA-AAA' in ec_info_dict.keys() or '7OVA' in ec_info_dict.keys():\n",
    "    print(\"7OVA-AAA\")\n",
    "go_uniprot_dict, go_info_dict = gen_protein_property_uniprots(json_dirs[1])\n",
    "pp_uniprot_dict, pp_info_dict = gen_protein_property_uniprots(json_dirs[2], single=False)\n",
    "pl_uniprot_dict, pl_info_dict = gen_protein_property_uniprots(json_dirs[3], single=False)\n",
    "print(\"Number of samples pl, pp, ec, go:\", len(pl_info_dict), len(pp_info_dict), len(ec_info_dict), len(go_info_dict))\n",
    "ec_labels = gen_ec_labels()\n",
    "go_labels, go_full_uniprot_dict = gen_go_labels(go_uniprot_dict)\n",
    "ppi_labels = gen_ppi_labels()\n",
    "lba_labels = gen_lba_labels()\n",
    "print(len(ec_uniprot_dict), len(go_uniprot_dict), len(pp_uniprot_dict), len(pl_uniprot_dict))\n",
    "train_list_pp, test_list_pp, test_uniprots_1 = gen_train_test_ids(pp_uniprot_dict, ec_uniprot_dict, go_full_uniprot_dict)\n",
    "train_list_pl, test_list_pl, test_uniprots_2 = gen_train_test_ids(pl_uniprot_dict, ec_uniprot_dict, go_full_uniprot_dict)\n",
    "test_list_all = list(set(test_list_pl + test_list_pp))\n",
    "test_uniprots_all = list(set(test_uniprots_1 + test_uniprots_2))\n",
    "\n",
    "# full_train_ratio = 0.2\n",
    "# full_val_ratio = 0.4\n",
    "# full_test_ratio = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in pl_info_dict.items():\n",
    "    if '1A5H-A' in value:\n",
    "        print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37400\n",
      "Train List: 19115 28482 6634 46837\n",
      "Process finished, saving information into ./dataset/MultiTaskNew/\n",
      "Saving split information...\n"
     ]
    }
   ],
   "source": [
    "reaction_uniprot_dict,reaction_info_dict = gen_reaction_uniprots()\n",
    "reaction_labels = gen_reaction_labels()\n",
    "# print(len(ec_uniprot_dict), len(go_uniprot_dict), len(pp_uniprot_dict), len(pl_uniprot_dict))\n",
    "train_list_pp, test_list_pp, test_uniprots_1 = gen_train_test_ids_new(pp_uniprot_dict, ec_uniprot_dict, go_full_uniprot_dict,reaction_dict=reaction_uniprot_dict)\n",
    "train_list_pl, test_list_pl, test_uniprots_2 = gen_train_test_ids_new(pl_uniprot_dict, ec_uniprot_dict, go_full_uniprot_dict,reaction_dict=reaction_uniprot_dict)\n",
    "test_list_all = list(set(test_list_pl + test_list_pp))\n",
    "test_uniprots_all = list(set(test_uniprots_1 + test_uniprots_2))\n",
    "\n",
    "# full_train_ratio = 0.2\n",
    "# full_val_ratio = 0.4\n",
    "# full_test_ratio = 0.4\n",
    "random.shuffle(test_list_pl)\n",
    "random.shuffle(test_list_pp)\n",
    "\n",
    "full_test_list = test_list_pl[int(0.6*len(test_list_pl)):] + test_list_pp[int(0.6*len(test_list_pp)):]\n",
    "full_val_list = test_list_pl[int(0.2*len(test_list_pl)): int(0.6*(len(test_list_pl)))] + test_list_pp[int(0.2*len(test_list_pp)): int(0.6*len(test_list_pp))]\n",
    "full_train_list = test_list_pl[: int(0.2*len(test_list_pl))] + test_list_pp[: int(0.2*len(test_list_pp))]\n",
    "\n",
    "train_list_ec = [ec_uniprot_dict[i] for i in ec_uniprot_dict if i not in test_uniprots_all]\n",
    "train_list_go = [go_uniprot_dict[i] for i in go_uniprot_dict if i not in test_uniprots_all]\n",
    "train_list_reaction = [reaction_uniprot_dict[i] for i in reaction_uniprot_dict if i not in test_uniprots_all]\n",
    "\n",
    "\n",
    "# train_list_pl:有pl label但是ec或者go缺点啥的pdb id训练集\n",
    "# train_list_pp:有pp label但是ec或者go缺点啥的训练集\n",
    "# train_list_ec:有ec但是没有go的训练集\n",
    "# train_list_go:有go但是没有ec的训练集\n",
    "train_list_all = list(set(train_list_pl + train_list_pp + train_list_ec + train_list_go +train_list_reaction+ full_train_list))\n",
    "print(\"Train List:\", len(train_list_ec), len(train_list_go),len(train_list_reaction),len(train_list_all))\n",
    "# train/val/test.txt contains samples of full labels, while train_all.txt contains labals with partial labels and samples in train.txt.\n",
    "print(\"Process finished, saving information into ./dataset/MultiTask_new/\")\n",
    "if os.path.exists('./datasets/MultiTask_new/train_all.txt') and os.path.exists('./datasets/MultiTask/tmp/train.txt'):\n",
    "    print(\"File already exists, skip saving split information...\")\n",
    "else:\n",
    "    print(\"Saving split information...\")\n",
    "    os.makedirs('./datasets/MultiTask_new', exist_ok=True)\n",
    "    save_dataset_info('./datasets/MultiTask_new/train_all.txt', train_list_all)\n",
    "    save_dataset_info('./datasets/MultiTask_new/train.txt', full_train_list)\n",
    "    save_dataset_info('./datasets/MultiTask_new/val.txt', full_val_list)\n",
    "    save_dataset_info('./datasets/MultiTask_new/test.txt', full_test_list)\n",
    "\n",
    "# uniformed_label_dict = gen_label(train_list_all+full_test_list+full_val_list, ec_labels, go_labels, ppi_labels, lba_labels, ec_uniprot_dict, go_uniprot_dict, ec_info_dict, go_info_dict, pp_info_dict, pl_info_dict)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of the processed unified label:\n",
      " 1ndy :  {'uniprots': ['P56658'], 'ec': [[2791]], 'go': [{'molecular_functions': [241, 306, 274], 'biological_process': [929, 690, 1158], 'cellular_component': [1, 71, 215, 170, 129, 212, 183]}], 'reaction': [[154]], 'ppi': -1, 'lba': 6.17}\n",
      "Generating uniformed labels...\n"
     ]
    }
   ],
   "source": [
    "uniformed_label_dict = gen_label_new(train_list_all+full_test_list+full_val_list,ec_labels, go_labels,reaction_labels,ppi_labels, lba_labels,ec_uniprot_dict, go_uniprot_dict,reaction_uniprot_dict,ec_info_dict,go_info_dict,reaction_info_dict,pp_info_dict,pl_info_dict)\n",
    "print(\"An example of the processed unified label:\\n\", full_test_list[0], \": \", uniformed_label_dict[full_test_list[0]])\n",
    "if os.path.exists('./datasets/MultiTask_new/uniformed_labels.json'):\n",
    "    print(\"File already exists, skip saving uniformed labels...\")\n",
    "else:\n",
    "    print('Generating uniformed labels...')\n",
    "    with open('./datasets/MultiTask_new/uniformed_labels.json', 'w') as f:\n",
    "        json.dump(uniformed_label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1210]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_labels = gen_ec_labels()\n",
    "ec_labels['1A5H-A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32554\n"
     ]
    }
   ],
   "source": [
    "go_task_dic = {}\n",
    "for k, v in go_uniprot_dict.items():\n",
    "    go_task_dic[v] = [k]\n",
    "print(len(go_task_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output_info/go_task_uniprots.json', 'w') as f:\n",
    "    json.dump(go_task_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2PGF-A'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_uniprot_dict['A5KE01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548 122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train List: 15267 32133\n",
      "Process finished, saving information into ./dataset/MultiTask_go/\n",
      "Saving split information...\n",
      "ok\n",
      "7NS4-b\n",
      "6A12-A\n",
      "['Q8L1V2']\n",
      "6A12-A\n",
      "go 6A12-A\n",
      "7NS4-i\n",
      "An example of the processed unified label:\n",
      " 2zdm :  {'uniprots': ['P00760'], 'ec': [[23, 27]], 'go': [{'molecular_functions': [3913, 4714, 4014, 3938, 3247, 459, 1269, 1849], 'biological_process': [4961, 4977], 'cellular_component': [343, 986, 1466]}], 'ppi': -1, 'lba': 6.41}\n",
      "File already exists, skip saving uniformed labels...\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(test_list_pl)\n",
    "random.shuffle(test_list_pp)\n",
    "print(len(test_list_pl), len(test_list_pp))\n",
    "full_test_list = test_list_pl[int(0.6*len(test_list_pl)):] + test_list_pp[int(0.6*len(test_list_pp)):]\n",
    "full_val_list = test_list_pl[int(0.2*len(test_list_pl)): int(0.6*(len(test_list_pl)))] + test_list_pp[int(0.2*len(test_list_pp)): int(0.6*len(test_list_pp))]\n",
    "full_train_list = test_list_pl[: int(0.2*len(test_list_pl))] + test_list_pp[: int(0.2*len(test_list_pp))]\n",
    "\n",
    "train_list_ec = [ec_uniprot_dict[i] for i in ec_uniprot_dict if i not in test_uniprots_all]\n",
    "train_list_go = [go_uniprot_dict[i] for i in go_uniprot_dict if i not in test_uniprots_all]\n",
    "print(\"Train List:\", len(train_list_ec), len(train_list_go))\n",
    "train_list_all = list(set(train_list_pl + train_list_pp + train_list_ec + train_list_go + full_train_list))\n",
    "\n",
    "# train/val/test.txt contains samples of full labels, while train_all.txt contains labals with partial labels and samples in train.txt.\n",
    "print(\"Process finished, saving information into ./dataset/MultiTask_go/\")\n",
    "if os.path.exists('./datasets/MultiTask_go/train_all.txt') and os.path.exists('./datasets/MultiTask_go/tmp/train.txt'):\n",
    "    print(\"File already exists, skip saving split information...\")\n",
    "else:\n",
    "    print(\"Saving split information...\")\n",
    "    os.makedirs('./datasets/MultiTask_go', exist_ok=True)\n",
    "    save_dataset_info('./datasets/MultiTask_go/train_all.txt', train_list_all)\n",
    "    save_dataset_info('./datasets/MultiTask_go/train.txt', full_train_list)\n",
    "    save_dataset_info('./datasets/MultiTask_go/val.txt', full_val_list)\n",
    "    save_dataset_info('./datasets/MultiTask_go/test.txt', full_test_list)\n",
    "    \n",
    "# print(go_labels)\n",
    "all_list = train_list_all+full_test_list+full_val_list\n",
    "if '6A12-A' in all_list:\n",
    "    print(\"ok\")\n",
    "uniformed_label_dict = gen_label(train_list_all+full_test_list+full_val_list, ec_labels, go_labels, ppi_labels, lba_labels, ec_uniprot_dict, go_uniprot_dict, ec_info_dict, go_info_dict, pp_info_dict, pl_info_dict)    \n",
    "print(\"An example of the processed unified label:\\n\", full_test_list[0], \": \", uniformed_label_dict[full_test_list[0]])\n",
    "if os.path.exists('./datasets/MultiTask_go/uniformed_labels.json'):\n",
    "    print(\"File already exists, skip saving uniformed labels...\")\n",
    "else:\n",
    "    print('Generating uniformed labels...')\n",
    "    with open('./datasets/MultiTask_go/uniformed_labels.json', 'w') as f:\n",
    "        json.dump(uniformed_label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "all_list = train_list_all+full_test_list+full_val_list\n",
    "if '101M-A' in train_list_go:\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48217/48217 [00:00<00:00, 359480.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(uniformed_label_dict.items()):\n",
    "    if '-' in key and len(value['uniprots']) > 1:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101M-A\n"
     ]
    }
   ],
   "source": [
    "go_annot_dir = './data/GO/nrPDB-GO_annot.tsv'\n",
    "with open(go_annot_dir, 'r') as f:\n",
    "    go_annots = f.readlines()\n",
    "label_dict = {'molecular_functions':{}, 'biological_process':{}, 'cellular_component':{}}\n",
    "pdb_annot_dict = {}\n",
    "label_id_molecular = 0\n",
    "label_id_biological = 0\n",
    "label_id_cellular = 0\n",
    "full_ids = []\n",
    "full_uniprot_dict = {}\n",
    "go_classes_molecular_functions = go_annots[1].strip().split('\\t')\n",
    "go_classes_biological_process = go_annots[5].strip().split('\\t')\n",
    "go_classes_cellular_component = go_annots[9].strip().split('\\t')\n",
    "for label in go_classes_molecular_functions:\n",
    "    if label not in label_dict['molecular_functions']:\n",
    "        label_dict['molecular_functions'][label] = label_id_molecular\n",
    "        label_id_molecular += 1\n",
    "for label in go_classes_biological_process:\n",
    "    if label not in label_dict['biological_process']:\n",
    "        label_dict['biological_process'][label] = label_id_biological\n",
    "        label_id_biological += 1\n",
    "for label in go_classes_cellular_component:\n",
    "    if label not in label_dict['cellular_component']:\n",
    "        label_dict['cellular_component'][label] = label_id_cellular\n",
    "        label_id_cellular += 1\n",
    "for annot in go_annots[12:]:\n",
    "    pdb_id, mf, bp, cc = annot.split('\\t')\n",
    "    if pdb_id[:4] == '101M':\n",
    "        print(pdb_id)\n",
    "    if pdb_id in uniformed_label_dict.keys():\n",
    "        molecular_list  = mf.strip().split(',')\n",
    "        biological_list = bp.strip().split(',')\n",
    "        cellular_list = cc.strip().split(',')\n",
    "        # print(molecular_list)\n",
    "        # 列表中会包含一些空的信息\n",
    "        uniformed_label_dict[pdb_id]['go'] = [{'molecular_functions':[label_dict['molecular_functions'][annot] for annot in molecular_list if annot != ''],\n",
    "                                'biological_process':[label_dict['biological_process'][annot] for annot in biological_list if annot != ''],\n",
    "                                'cellular_component':[label_dict['cellular_component'][annot] for annot in cellular_list if annot != '']}]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/MultiTaskNew/uniformed_labels.json', 'w') as f:\n",
    "    json.dump(uniformed_label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uniprots': ['P18946'],\n",
       " 'ec': [-1],\n",
       " 'go': [{'molecular_functions': [4714, 4354],\n",
       "   'biological_process': [6431, 7623],\n",
       "   'cellular_component': []}],\n",
       " 'ppi': -1,\n",
       " 'lba': -1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniformed_label_dict['101M-A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2qw1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_pl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if '101M-A' in train_list_ec:\n",
    "    print(\"yes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_gmsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
